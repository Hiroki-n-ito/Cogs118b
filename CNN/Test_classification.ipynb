{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing using 3 datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 15:01:10.057332: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sn\n",
    "\n",
    "from skimage.feature import graycoprops, graycomatrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dir_name):\n",
    "\n",
    "    img_list = []\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "    for item in os.listdir(dir_name):\n",
    "\n",
    "        img_path = os.path.join(dir_name, item)\n",
    "        #print(img_path)\n",
    "\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (224,224), interpolation = cv2.INTER_AREA)\n",
    "        img = cv2.GaussianBlur(img, (5,5), 1)\n",
    "\n",
    "        img = clahe.apply(img)\n",
    "        \n",
    "        img_list.append(img)\n",
    "\n",
    "    \n",
    "    return img_list\n",
    " \n",
    "\n",
    "def img_to_array(img):\n",
    "    \n",
    "    \n",
    "    img = np.asarray(img)\n",
    "    return img\n",
    "  \n",
    "def find_edges(img_list):\n",
    "    shape = img_list.shape\n",
    "    new_arr = np.zeros(shape=shape)\n",
    "    new_list = []\n",
    "    for i, img in enumerate(img_list):\n",
    "        if len(new_list) == 3:\n",
    "            new_list = []\n",
    "        v = np.median(img)\n",
    "        sigma = 0.33\n",
    "\n",
    "\n",
    "        if img.dtype != 'uint8':\n",
    "            img = img.astype('uint8')\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        lower = int(max(0, (1.0 - sigma) * v))\n",
    "        upper = int(max(0, (1.0 + sigma) * v))\n",
    "\n",
    "        img = cv2.Canny(img, lower, upper)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        new_list.append(img)\n",
    "        if len(new_list) == 3:\n",
    "            new_arr[i] = img\n",
    "\n",
    "    # print(new_list)\n",
    "    return new_arr\n",
    "\n",
    "def find_edge(img):\n",
    "    v = np.median(img)\n",
    "    sigma = 0.33\n",
    "\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(max(0, (1.0 + sigma) * v))\n",
    "\n",
    "    img = cv2.Canny(img, lower, upper)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_features(image_list):\n",
    "    for i in range(len(image_list)):\n",
    "        img_rgb = image_list[i]  # RGB image\n",
    "        img_gray = rgb2gray(img_rgb)  # Convert to grayscale\n",
    "        image_list[i] = (img_gray * 255).astype('uint8')\n",
    "    feature_list = []\n",
    "\n",
    "    distances = [1,3,5,9]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4, np.pi, 5*np.pi/4, 3*np.pi/2]\n",
    "\n",
    "    properties = ['energy', 'correlation', 'dissimilarity', 'homogeneity', 'contrast']\n",
    "\n",
    "    # need to add more distances (1,3,5,9)\n",
    "    for n, img in enumerate(image_list):\n",
    "        glcm = graycomatrix(img, distances, angles , levels=256, normed=True)\n",
    "        feature_row = {}\n",
    "\n",
    "        for prop in properties:\n",
    "            prop_values = graycoprops(glcm, prop)   \n",
    "            for i, dist in enumerate(distances):\n",
    "                for j, angle in enumerate(angles): \n",
    "                    feature_name = f\"{prop}_d{dist}_a{int(np.degrees(angle))}\"\n",
    "                    feature_row[feature_name] = prop_values[i, j]\n",
    "\n",
    "        feature_list.append(feature_row)\n",
    "    return feature_list\n",
    "\n",
    "def view_corr(df):\n",
    "    corr_matrix = df.corr()\n",
    "    sns.heatmap(corr_matrix)\n",
    "    plt.show()\n",
    "\n",
    "def pca_df_pick_comp(df):\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(df)\n",
    "\n",
    "    pca = PCA()\n",
    "    pca_features = pca.fit_transform(scaled_features)\n",
    "\n",
    "    pca_df = pd.DataFrame(pca_features, columns=[f\"PC{i+1}\" for i in range(pca.n_components_)])\n",
    "\n",
    "    pca_tot = pca_df\n",
    "    plt.plot(range(1,len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_.cumsum())\n",
    "    plt.xlabel(\"Num of components\")\n",
    "    plt.ylabel('Cumulative exlpained by variance')\n",
    "    plt.title('explained variance by pca components')\n",
    "    plt.show()\n",
    "\n",
    "    cumulative_var = pca.explained_variance_ratio_.cumsum()\n",
    "    n_components = 0\n",
    "\n",
    "    for i, var in enumerate(cumulative_var):\n",
    "        if var >= 0.95:\n",
    "            n_components = i + 1\n",
    "            break\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(scaled_features)\n",
    "\n",
    "    pca_columns = [f\"PC{i+1}\" for i in range(n_components)]\n",
    "    pca_df= pd.DataFrame(reduced_features, columns=pca_columns)\n",
    "\n",
    "    return pca_df, pca_tot\n",
    "\n",
    "def load_images_resnet(dir_name):\n",
    "\n",
    "    img = cv2.imread(dir_name)\n",
    "\n",
    "    img = find_edge(img)\n",
    "    img = cv2.GaussianBlur(img, (5,5), 1)\n",
    "\n",
    "    #might need to add clahe\n",
    "   \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img / 255\n",
    "\n",
    "\n",
    "    #normalize\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = (img-mean) / std\n",
    "    img = np.transpose(img, (2, 0 , 1))\n",
    "    img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "def extract_features_resnet(dir_name, model):\n",
    "   \n",
    "    img_tensor = load_images_resnet(dir_name)\n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor)\n",
    "    return features.squeeze().numpy()\n",
    "\n",
    "\n",
    "\n",
    "def find_edge(img):\n",
    "    # Placeholder for edge detection logic (if necessary)\n",
    "    return img\n",
    "\n",
    "def load_images_resnet(dir_name):\n",
    "    # Read the image\n",
    "    img = cv2.imread(dir_name)\n",
    "\n",
    "    # Apply edge detection (if required)\n",
    "    img = find_edge(img)\n",
    "    img = cv2.GaussianBlur(img, (5, 5), 1)\n",
    "\n",
    "    # Resize to 224x224\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    img = img / 255.0\n",
    "\n",
    "    # Normalize image using ImageNet mean and std (per channel)\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    # Apply normalization across the 3 channels (HWC format)\n",
    "    img = (img - mean) / std  # Broadcasting will apply to each channel\n",
    "\n",
    "    # Convert from HWC to CHW format (for PyTorch) - this will be used for PyTorch models\n",
    "    img_tensor = np.transpose(img, (2, 0, 1))  # Shape will be (3, 224, 224)\n",
    "    \n",
    "    # Convert to tensor (PyTorch format)\n",
    "    img_tensor = torch.tensor(img_tensor, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
    "    return img_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"./data_xray/Impacted fracture\"\n",
    "list_1 = []\n",
    "\n",
    "for img_name in os.listdir(dir_name):\n",
    "    img_path = os.path.join(dir_name, img_name)\n",
    "    \n",
    "    if img_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        feature = load_images_resnet(img_path)\n",
    "        list_1.append(feature)\n",
    "\n",
    "for i in range(len(list_1)):\n",
    "    img_tensor = list_1[i]\n",
    "\n",
    "    img_tensor = img_tensor.squeeze(0) \n",
    "    img_tensor = img_tensor.permute(1, 2, 0)  \n",
    "    img = img_tensor.numpy()\n",
    "    list_1[i] = img\n",
    "\n",
    "dir_name = \"./data_xray/Intra-articular fracture\"\n",
    "list_2 = []\n",
    "\n",
    "for img_name in os.listdir(dir_name):\n",
    "    img_path = os.path.join(dir_name, img_name)\n",
    "    \n",
    "    if img_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        feature = load_images_resnet(img_path)\n",
    "        list_2.append(feature)\n",
    "\n",
    "for i in range(len(list_2)):\n",
    "    img_tensor = list_2[i]\n",
    "\n",
    "    img_tensor = img_tensor.squeeze(0) \n",
    "    img_tensor = img_tensor.permute(1, 2, 0)  \n",
    "    img = img_tensor.numpy()\n",
    "    list_2[i] = img\n",
    "\n",
    "    dir_name = \"./data_xray/Longitudinal fracture\"\n",
    "list_3 = []\n",
    "\n",
    "for img_name in os.listdir(dir_name):\n",
    "    img_path = os.path.join(dir_name, img_name)\n",
    "    \n",
    "    if img_path.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        feature = load_images_resnet(img_path)\n",
    "        list_3.append(feature)\n",
    "\n",
    "for i in range(len(list_3)):\n",
    "    img_tensor = list_3[i]\n",
    "\n",
    "    img_tensor = img_tensor.squeeze(0) \n",
    "    img_tensor = img_tensor.permute(1, 2, 0)  \n",
    "    img = img_tensor.numpy()\n",
    "    list_3[i] = img\n",
    "list_1 = get_features(list_1)\n",
    "list_2 = get_features(list_2)\n",
    "list_3 = get_features(list_3)\n",
    "\n",
    "impacted = pd.DataFrame(list_1)\n",
    "impacted['target'] = 0\n",
    "\n",
    "intra_artic = pd.DataFrame(list_2)\n",
    "intra_artic['target'] = 1\n",
    "\n",
    "longitudinal = pd.DataFrame(list_3)\n",
    "longitudinal['target'] = 2\n",
    "\n",
    "\n",
    "data_df_resnet = pd.concat([impacted,intra_artic,longitudinal], axis=0)\n",
    "X = data_df_resnet.iloc[:, :-1]\n",
    "Y = data_df_resnet.iloc[:, -1]\n",
    "\n",
    "print(impacted.shape, intra_artic.shape, longitudinal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('./data_xray')\n",
    "data = data.shuffle(len(data))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "\n",
    "def extract_images_and_labels(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_batch, label_batch in dataset:\n",
    "        images.append(image_batch.numpy()) \n",
    "        labels.append(label_batch.numpy()) \n",
    "    \n",
    "    images = np.concatenate(images, axis=0)  # Concatenate all batches to form a single numpy array\n",
    "    images = find_edges(images)\n",
    "    labels = np.concatenate(labels, axis=0)  # Concatenate all labels\n",
    "    return images, labels\n",
    "\n",
    "all_images, all_labels = extract_images_and_labels(data)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.3, stratify=all_labels)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.3, stratify=y_temp)\n",
    "\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'x_val shape: {x_val.shape}, y_val shape: {y_val.shape}')\n",
    "print(f'x_test shape: {x_test.shape}, y_test shape: {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# y_train, y_val, y_test = None\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 3)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
    "\n",
    "print(y_train.sum(axis = 0))\n",
    "print(y_val.sum(axis = 0))\n",
    "print(y_test.sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='log'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=10, validation_data=(x_val,y_val), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(location):\n",
    "    img = x_test[location]\n",
    "    true_label = y_test[location]\n",
    "\n",
    "    resize = tf.image.resize(np.expand_dims(img, 0), (256, 256))\n",
    "    yhat = model.predict(resize / 255.0)\n",
    "    predicted_class = np.argmax(yhat, axis=-1)[0]\n",
    "    class_names = ['Impacted Fracture', 'Intra-Articular Fracture', 'Longitudinal Fracture', 'Oblique Fracture']\n",
    "    print(f'Predicted class: {class_names[predicted_class]}')\n",
    "\n",
    "    \n",
    "    true_class = np.argmax(true_label)\n",
    "    print(f'True class: {class_names[true_class]}')\n",
    "\n",
    "    if class_names[predicted_class] == class_names[true_class]:\n",
    "        # print('Correct')\n",
    "        count = 1\n",
    "    else:\n",
    "        # print('Incorrect')\n",
    "        count = 0\n",
    "    return count\n",
    "\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 0\n",
    "for i in range(len(y_test)):\n",
    "    counter = test_function(i);\n",
    "    val += counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val)\n",
    "y_test.sum(axis = 0)\n",
    "print(y_test.sum(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Animal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = model.fit(x_train, y_train,validation_data= (x_val,y_val),epochs = 9, class_weight=class_weights_dict)\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "y_test_labels = np.argmax(y_test, axis=1)  # Ground truth labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)  # Predicted labels\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "precision = precision_score(y_test_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_test_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1-Score: {f1 * 100:.2f}%\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "class_names = ['Class 1', 'Class 2', 'Class 3']  # Replace with actual class names\n",
    "\n",
    "# Plot confusion matrix\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.set(font_scale=1.2)\n",
    "sn.heatmap(df_cm, annot=True, cmap=\"Blues\", fmt=\"d\", annot_kws={\"size\": 14})\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 3 classes.\n",
      "x_train shape: (2100, 256, 256, 3), y_train shape: (2100,)\n",
      "x_val shape: (630, 256, 256, 3), y_val shape: (630,)\n",
      "x_test shape: (270, 256, 256, 3), y_test shape: (270,)\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('./Animals')\n",
    "data = data.shuffle(len(data))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "data = data.map(lambda x,y: (x/255, y))\n",
    "def extract_images_and_labels(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_batch, label_batch in dataset:\n",
    "        images.append(image_batch.numpy()) \n",
    "        labels.append(label_batch.numpy()) \n",
    "    \n",
    "    images = np.concatenate(images, axis=0)  # Concatenate all batches to form a single numpy array\n",
    "    # images = find_edges(images)\n",
    "    labels = np.concatenate(labels, axis=0)  # Concatenate all labels\n",
    "    return images, labels\n",
    "all_images, all_labels = extract_images_and_labels(data)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(all_images, all_labels, test_size=0.3, stratify=all_labels, shuffle=True)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.3, stratify=y_temp)\n",
    "\n",
    "print(f'x_train shape: {x_train.shape}, y_train shape: {y_train.shape}')\n",
    "print(f'x_val shape: {x_val.shape}, y_val shape: {y_val.shape}')\n",
    "print(f'x_test shape: {x_test.shape}, y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700. 700. 700.]\n",
      "[210. 210. 210.]\n",
      "[90. 90. 90.]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "# model.add(Dense(16, activation = 'relu'))\n",
    "# model.add(Dense(8, activation = 'relu'))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# y_train, y_val, y_test = None\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 3)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 3)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 3)\n",
    "\n",
    "print(y_train.sum(axis = 0))\n",
    "print(y_val.sum(axis = 0))\n",
    "print(y_test.sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "66/66 [==============================] - 62s 903ms/step - loss: 0.8450 - accuracy: 0.5924 - val_loss: 0.8376 - val_accuracy: 0.5619\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 59s 890ms/step - loss: 0.7234 - accuracy: 0.6567 - val_loss: 0.8136 - val_accuracy: 0.6063\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 58s 879ms/step - loss: 0.6316 - accuracy: 0.7033 - val_loss: 0.8668 - val_accuracy: 0.6143\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 56s 843ms/step - loss: 0.4380 - accuracy: 0.8133 - val_loss: 1.0813 - val_accuracy: 0.6016\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 56s 857ms/step - loss: 0.3248 - accuracy: 0.8724 - val_loss: 1.5093 - val_accuracy: 0.5937\n"
     ]
    }
   ],
   "source": [
    "logdir='log'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=5, validation_data=(x_val,y_val), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(np.argmax(y_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 9s 384ms/step\n",
      "[[0.3217345  0.32529882 0.3529667 ]\n",
      " [0.39146355 0.38184425 0.2266922 ]\n",
      " [0.39170858 0.37968695 0.22860444]\n",
      " [0.39209932 0.37966508 0.22823568]\n",
      " [0.39853066 0.39007595 0.21139339]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_val)\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogs118",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
